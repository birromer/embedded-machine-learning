#+TITLE: Embedded Machine Learning

* Introduction
This project aims at implementing and testing machine learning algorithms adapted for an embedded environment. The following classifiers were used:

- Classification and Regression Trees (CART)
- Support Vector Machines (SVM)
- Artificial Neural Networks (ANN)

The task at hand is the identification of musical styles, which is tackled using the [[https://www.kaggle.com/carlthome/gtzan-genre-collection][GTZAN Genre Collection]] dataset. Here, each audio file is stored using the [[https://en.wikipedia.org/wiki/Au_file_format][AU file format]]. A reader has been implemented for this file format, as well as a feature extraction using a [[https://en.wikipedia.org/wiki/Short-time_Fourier_transform#Discrete-time_STFT][Discrete Short-time Fourier transform]].

A full description of the project can be found in the [[https://gitlab.ensta-bretagne.fr/reynetol/embedded-machine-learning][original repository]], together with the base helper routines provided.

* Setup
The project is organized as follows:

#+begin_src bash :exports results :results output
tree -n -L 2 -I 'build|CMake*|__pycache__'
#+end_src

#+RESULTS:
#+begin_example
.
├── ANN
│   └── Python
├── CART
│   ├── CART.py
│   └── train_cart.py
├── DATA
│   ├── blues
│   ├── classical
│   ├── country
│   ├── disco
│   ├── features.csv
│   ├── features_prof.csv
│   ├── features_testing.csv
│   ├── features_training.csv
│   ├── file_list_test.txt
│   ├── file_list_train.txt
│   ├── hiphop
│   ├── jazz
│   ├── metal
│   ├── pop
│   ├── reggae
│   ├── rock
│   └── tests.org
├── Evaluation
│   ├── evaluate_cart.cpp
│   └── evaluation_svm.cpp
├── Extraction
│   ├── features_extraction.cpp
│   ├── features_extraction.h
│   └── main.cpp
├── Helpers
│   ├── au_reading.h
│   ├── etypes.h
│   ├── file_helpers.h
│   ├── globals.h
│   ├── music_style_helpers.cpp
│   ├── music_style_helpers.h
│   ├── print_helpers.h
│   ├── signal.h
│   └── wav_reading.h
├── readme.bash
├── readme.org
├── RF
├── setup.sh
└── SVM
    ├── music_styles_svm.cpp
    └── svm.py

19 directories, 28 files
#+end_example

Each of the classifiers has its folder (=ANN/=, =CART/=, =RF/=, =SVM/=) with a training script, usually in Python for it does not have to be embedded, and a classifier in C++.

- =DATA/= :: Contains the audio files from the dataset. They were not included because of their size, but this view shows the necessary organization for reproducible results.

- =Extraction/= :: Contains the feature extraction code, implemented only using STFT.

- =Helpers/= :: Contains a multitude of utilities, such as for signal processing, global definitions, and labels management.

- =Evaluation/= :: Contains programs that measure the accuracy, execution time and memory usage of the algorithms. They are invoked individually for each classifier.

=setup.sh= and =evaluation.sh= are the tangled snippets presented in this file, with everything up to model training in the former, and the performance evaluation in the latter.

** Requirements

All of the libraries used should be included in a standard building system installation. The only addition is [[https://www.tensorflow.org/][Tensorflow]], for training neural networks. Installation instructions can be found in the [[https://www.tensorflow.org/install/pip][official documentation]].

** Usage
The first step is to compile the source code, which can be done with the following block, working for both a personal computer and a Raspberry Pi board.

#+begin_src bash :tangle "setup.sh" :exports code :results silent :mkdirp yes
# build feature extraction
mkdir -p build/setup
cmake -S Extraction -B build/setup  # "Extraction" may be replaced by the desired module
make -C build/setup                 # or . for the entire project
#+end_src

Only the needed module is compiled now, as some files needed for further building the modules are generated in the following steps. An example is CART, which will only have its prediction tree after the training done in Python.

*** Feature extraction
The extraction of features from the audio files must happen before the training steps. In our case we'll be using only the dataset, which is split into training and testing data.

It outputs to the data folder the files =file_list_train.txt= and =file_list_test.txt=, with the file paths for training and testing. The testing one is the input for the evaluation binaries, if no other is provided.

The features are extracted to the files =features_training.csv= and =features_testing.csv=. They correspond to the aforementioned data and are already computed to avoid repeated calls.

Having the project built, the extraction can be executed with the following command:

#+begin_src bash :tangle "setup.sh" :exports code :results silent
# extract features
./build/setup/EXTRACTION
#+end_src

*** CART
In order to use the CART algorithm, you must first build the classification tree:

#+begin_src bash :tangle "setup.sh" :results silent
# train cart tree
python3 CART/train_cart.py
#+end_src

This will generate the file =CART/music_styles_cart.cpp=, with a function corresponding to a sequence of if/else's analog to the trained binary tree paths.

*** SVM
So to use the SVM model, we must first also execute the related Python script:

#+begin_src bash :tangle "setup.sh" :export code :results silent
# train svm model
python3 SVM/train_svm.py
#+end_src

This will generate the files =DATA/svm_coeff.csv=, with the weights and bias for the hyperplanes in the model, and =DATA/svm_feat_Stats.csv=, with the statistical attributes of the features used in training, so that it can be replicated during prediction.

*** ANN
The usage of the ANN method requires first the training of the associated neural network, also specified in a Python script:

#+begin_src bash :tangle "setup.sh" :export code
# train ann
python3 ANN/train_ann.py
#+end_src

<COMPLETE WITH OUTPUT WEIGHTS FILE>

*** Evaluation
In order to run the evaluation of the learning methods, it is necessary first to compile the Evaluation module, as in the following block:

#+begin_src bash :tangle "eval.sh" :export code :results silent
# build evaluation code
mkdir -p build/eval
cmake -S Evaluation -B build/eval
make -C build/eval
#+end_src

An executable is generated per method, with execution exemplified bellow:
#+begin_src bash :tangle "eval.sh" :export code :results silent
# CART evaluation
./build/eval/EVALUATION_CART

# SVM evaluation
./build/eval/EVALUATION_SVM

# ANN evaluation
#./build/eval/EVALUATION_SVM
#+end_src

In practice, the codes related to the prediction using each algorithm is stored in their respective folder, and it is used for this statistical performance analysis defined withing the Evaluation module.

* Development
The development of the present project has followed the order in

* Results
